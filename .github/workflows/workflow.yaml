name: DB Workflow

on:
  schedule:
    - cron: "0 * * * *"     # Jede volle Stunde Daten holen
    - cron: "5 0 * * *"     # Täglich um 00:05 kombinieren, bereinigen etc.
  workflow_dispatch:

permissions:
  contents: write

jobs:
  fetch_hourly:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0  # Holt den kompletten Verlauf, wichtig für rebase

      - name: Install Poetry
        run: pip install poetry

      - name: Install dependencies
        run: poetry install

      - name: Set environment variables
        run: |
          echo "DB_CLIENT_ID=${{ secrets.DB_CLIENT_ID }}" >> .env
          echo "DB_API_KEY=${{ secrets.DB_API_KEY }}" >> .env

      - name: Fetch Data Hourly
        run: poetry run python src/01_fetch_data.py

      # Vor dem Committen aktualisieren wir die lokale main mit remote main
      - name: Update local main with remote
        run: |
          git pull --rebase origin main

      - name: Configure Git
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

      - name: Commit and push changes (Hourly)
        run: |
          git add 01_data/01_raw/API/*.csv
          if git diff --cached --quiet; then
            echo "No hourly changes to commit."
          else
            git commit -m "Add hourly data files [skip ci]"
            git push origin HEAD:main
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  daily_combine_and_clean:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Install Poetry
        run: pip install poetry

      - name: Install dependencies
        run: poetry install

      - name: Set environment variables
        run: |
          echo "DB_CLIENT_ID=${{ secrets.DB_CLIENT_ID }}" >> .env
          echo "DB_API_KEY=${{ secrets.DB_API_KEY }}" >> .env

      - name: Combine Daily Data
        run: poetry run python src/03_combine_daily.py

      # Veränderungen für intermediate-Dateien committen
      - name: Update local main with remote (Daily Combine)
        run: |
          git pull --rebase origin main

      - name: Configure Git (Daily Combine)
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

      - name: Commit and push changes (Daily Combine)
        run: |
          git add 01_data/02_intermediate/*.csv
          if git diff --cached --quiet; then
            echo "No daily combined changes to commit."
          else
            git commit -m "Add daily combined data files [skip ci]"
            git push origin HEAD:main
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Determine yesterday's date
        run: echo "DATE=$(date -d 'yesterday' '+%y%m%d')" >> $GITHUB_ENV

      - name: Clean Data
        run: poetry run python src/02_clean_data.py ${{ env.DATE }}

      - name: Append to combined
        run: poetry run python src/04_append_to_combined.py ${{ env.DATE }}

      # Änderungen an combined.csv committen
      - name: Update local main with remote (Combined)
        run: |
          git pull --rebase origin main

      - name: Configure Git (Combined)
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

      - name: Commit and push changes (Combined CSV)
        run: |
          git add 01_data/03_processed/combined.csv
          if git diff --cached --quiet; then
            echo "No combined changes to commit."
          else
            git commit -m "Update combined.csv [skip ci]"
            git push origin HEAD:main
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
